{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c93881-b162-42c2-b48d-57c6207a029b",
   "metadata": {},
   "source": [
    "## 任务一：基于机器学习的文本分类\n",
    "\n",
    "实现基于logistic/softmax regression的文本分类\n",
    "\n",
    "1. 参考\n",
    "   1. [文本分类](文本分类.md)\n",
    "   2. 《[神经网络与深度学习](https://nndl.github.io/)》 第2/3章\n",
    "2. 数据集：[Classify the sentiment of sentences from the Rotten Tomatoes dataset](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)\n",
    "3. 实现要求：NumPy\n",
    "4. 需要了解的知识点：\n",
    "\n",
    "   1. 文本特征表示：Bag-of-Word，N-gram\n",
    "   2. 分类器：logistic/softmax  regression，损失函数、（随机）梯度下降、特征选择\n",
    "   3. 数据集：训练集/验证集/测试集的划分\n",
    "5. 实验：\n",
    "   1. 分析不同的特征、损失函数、学习率对最终分类性能的影响\n",
    "   2. shuffle 、batch、mini-batch \n",
    "6. 时间：两周\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a6bdf-bca7-40fa-9652-170dc89f3905",
   "metadata": {},
   "source": [
    "### 包导入\n",
    "- [jieba](https://www.cnblogs.com/ltb6w/p/10886416.html)：用于分词、统计词频等\n",
    "- sklearn.feature_extraction.text.CountVectorizer： 文本向量化\n",
    "- nltk:英文文本处理包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60be55ba-b5e0-48fa-97e4-fbb66fb6f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tqdm  # 进度表\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import  Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa536815-86a8-4533-af6f-d65bf25a9985",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb7aeee-5511-4f18-9d9a-3a2fb8996562",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './sentiment-analysis-on-movie-reviews/'\n",
    "\n",
    "# 创建Setence对象，存放每个句子的特征\n",
    "class Sentence:\n",
    "    def __init__(self,sentence,sentiment=None):\n",
    "        self.sentence = sentence\n",
    "        self.sentiment = sentiment\n",
    "        self.wordVector = None\n",
    "        self.sentiVector = [0,0,0,0,0]\n",
    "\n",
    "phraseSentimentMap = dict()  # 用于查询每个二元特征（2-gram）对应的情感\n",
    "sentenceList = []\n",
    "with open(path+'train.tsv') as f:\n",
    "    next(f) \n",
    "    oldSentenceId = 0\n",
    "    for content in f:\n",
    "        content = content.split('\\t')\n",
    "        # 以下四个变量分别为短语和句子id、短语以及短语的情感\n",
    "        try:\n",
    "            sentenceId,phrase,sentiment = (int(content[1]),content[2],int(content[3]))\n",
    "        except:\n",
    "            print(content[0],content[1],content[2],content[3])\n",
    "        # 采用二元特征（2-gram），建立短语-情感的映射\n",
    "        if len(phrase.split())<=2:\n",
    "            phrase.strip()\n",
    "            phraseSentimentMap[phrase] =  sentiment\n",
    "        # 如果是句子，则加入sentenceList\n",
    "        # 句子一般在同句子序号的第一位\n",
    "        if sentenceId != oldSentenceId:\n",
    "            sentenceList.append(Sentence(phrase,sentiment))\n",
    "            oldSentenceId = sentenceId          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977c6a6-92d3-4c1b-b75d-8b4050d59fd0",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f9fa67-864c-495f-9a84-9e4199c817d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3句是：\n",
      "A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder of a Shakespearean tragedy or a juicy soap opera .\n",
      "它的情感分类是:3\n",
      "短语库的大小是42491,句子库的大小是8529\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "print('第{0}句是：\\n{1}\\n它的情感分类是:{2}'.format(i,sentenceList[i].sentence,sentenceList[i].sentiment))\n",
    "print('短语库的大小是{0},句子库的大小是{1}'.format(len(phraseSentimentMap),len(sentenceList)))\n",
    "# print(phraseSentimentMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5786e6a-8ae3-45c5-b8c6-7b358e19e22a",
   "metadata": {},
   "source": [
    "- [关于迭代变量、迭代器、\\_\\_iter\\_\\_()和next()方法的关系](https://blog.csdn.net/Jairoguo/article/details/104483824)\n",
    "    - 简而言之，list自身不是迭代器，但他可以用iter()方法返回一个list_iterator迭代器\n",
    "    - 任何迭代器都有__iter__()和__next__()两种方法，分别用于返回自身和进行下一步操作，返回值\n",
    "    - 迭代器第一次调用__next__()返回的是第一项而不是第二项 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498ccb3-90fc-48cc-b710-c1e04ab6d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 关于next的讨论\n",
    "# # 说明：__iter__返回一个迭代器（类似指针，指向a的首部），赋给其他变量调用next方法后会指向下一个部分\n",
    "# # 注意list本身没有next()方法\n",
    "# a = [1,2,3]\n",
    "#n = a.__iter__()\n",
    "# print('a.__iter()__的返回值为 {0}'.format(n))\n",
    "# print('a.__iter()__的地址为 {0}'.format(id(a.__iter__())))\n",
    "# print('连续调用n【a返回的迭代器】效果')\n",
    "# print(next(n))\n",
    "# print(id(n))\n",
    "# print(next(n))\n",
    "# print(id(n))\n",
    "# print(next(n))\n",
    "# print(id(n))\n",
    "# print(next(a.__iter__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064d70c-526c-49b9-904c-cf6a190cf2df",
   "metadata": {},
   "source": [
    "### 先试着用单词情感作为特征进行预测\n",
    "考虑到数据库的短语很多，特征不见得很明显；而直接用构成句子的单词具有的情感作为特征，只需要5维，机器学习更快，而且该输入和输出相关性很强，  \n",
    "所以先试着用每个句子2-gram的5类情感数目作为输入，句子的情感作为输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64d0b5-6e1d-4796-a3bb-9d14010f4c75",
   "metadata": {},
   "source": [
    "#### 1. 确定每个句子的情感矢量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0314d9c-8fd6-4599-ad3f-26d762571170",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentVectors = []\n",
    "for s in sentenceList:\n",
    "    tokens = s.sentence.split()\n",
    "    tokens2 = list(' '.join(w) for w in nltk.ngrams(tokens, 2))\n",
    "    vector = np.zeros(5)\n",
    "    for token in tokens2:\n",
    "        if token in phraseSentimentMap:\n",
    "            vector[phraseSentimentMap[token]] += 1\n",
    "    sentimentVectors.append(vector)\n",
    "sentimentVectors = np.array(sentimentVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b10a89-c8bb-43eb-9fd6-3eae77b87012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. 10.  1.  0.]\n",
      " [ 0.  0.  1.  1.  0.]\n",
      " [ 0.  1.  6.  0.  0.]\n",
      " [ 0.  1.  6.  1.  0.]\n",
      " [ 0.  2.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(sentimentVectors[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9f96e-3f33-4276-beef-40c6b3e9c153",
   "metadata": {},
   "source": [
    "#### 2.确定输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959281d7-2932-41b4-b1e9-1be3d36993ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = np.array([s.sentiment for s in sentenceList])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c23e3c-4a29-43bc-b0ec-ffe9e1de7f1b",
   "metadata": {},
   "source": [
    "#### 3. 现在我们有了输入和输出，可以开始进行训练了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde84d1-70c2-4a23-9c23-e76ea6029e2c",
   "metadata": {},
   "source": [
    "划分训练集和测试集（kaggle提供的测试集没有标签，所以想知道模型性能得自己划分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9570d962-6795-462c-8c6c-636670a3e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6396, 5) (2133, 5)\n",
      "Counter({3: 1738, 1: 1655, 2: 1246, 4: 957, 0: 800})\n",
      "Counter({3: 583, 1: 545, 2: 409, 4: 324, 0: 272})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentimentVectors, Labels)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ebec4-f812-4861-9a8f-a80fe21ca073",
   "metadata": {},
   "source": [
    "数据预处理：[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)  \n",
    "说明：\n",
    "1. 可能会改变不同标签的大小相对关系（比如变换前[5,1],变换后[0.5,0.4],但空间上看不影响分类，因为是线性变换）\n",
    "2. 归一化绝对有必要，一来可以加快训练速度【参考吴恩达dl课程】；二来可以防止尺度不一致造成的影响，如本题特征2数最大，相较而言其他数比较小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce18f4c8-a317-40d9-9236-10874e652a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() # 构造尺度转化对象scaler\n",
    "X_train = scaler.fit_transform(X_train)  # fit是找出数据的某些特征，transform是基于数据的特征进行转化，注意只有训练集用fit_transform方法\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329afe9d-43be-4e65-b7fd-087b38a70620",
   "metadata": {},
   "source": [
    "采用softmax训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052196dc-e882-4883-85f8-b28a54988b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression( C= 0.5,class_weight = None)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891af2a7-cf63-4d91-80d0-fd1c12eb0a6c",
   "metadata": {},
   "source": [
    "#### 3. 预测并评估结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0847b6-bf45-4933-869c-290a9276ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb54b15c-7629-4dbf-a0a6-3987af122241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1075, 3: 789, 4: 161, 0: 108})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eced9e06-2718-48bf-b210-5c7d47fc0743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2133,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b0a3ee-8f20-4e5a-a49b-b5f18418e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.19      0.28       272\n",
      "           1       0.33      0.66      0.44       545\n",
      "           2       0.00      0.00      0.00       409\n",
      "           3       0.40      0.54      0.46       583\n",
      "           4       0.53      0.27      0.35       324\n",
      "\n",
      "    accuracy                           0.38      2133\n",
      "   macro avg       0.35      0.33      0.31      2133\n",
      "weighted avg       0.34      0.38      0.33      2133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd1220-a253-4916-ac05-ba415b5780d7",
   "metadata": {},
   "source": [
    "#### 4.用贝叶斯分类再做一次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd037a8-2a4c-419b-9f30-d93f73fe9b87",
   "metadata": {},
   "source": [
    "预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "035a9bab-1a33-4b8f-81df-b0d6255a3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentimentVectors, Labels)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() # 构造尺度转化对象scaler\n",
    "X_train = scaler.fit_transform(X_train)  # fit是找出数据的某些特征，transform是基于数据的特征进行转化，注意只有训练集用fit_transform方法\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a439ae9-df7f-4e37-9522-63253a077b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 570, 2: 506, 4: 371, 1: 356, 0: 330})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.30      0.27       270\n",
      "           1       0.33      0.22      0.27       542\n",
      "           2       0.24      0.30      0.26       402\n",
      "           3       0.33      0.31      0.32       609\n",
      "           4       0.32      0.38      0.35       310\n",
      "\n",
      "    accuracy                           0.29      2133\n",
      "   macro avg       0.29      0.30      0.29      2133\n",
      "weighted avg       0.30      0.29      0.29      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "# 学习\n",
    "model_2 = NuSVC()\n",
    "model_2.fit(X_train,y_train)\n",
    "# 预测\n",
    "predict = model_2.predict(X_test)\n",
    "print(Counter(predict))\n",
    "# 评价\n",
    "print(classification_report(y_test, predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
